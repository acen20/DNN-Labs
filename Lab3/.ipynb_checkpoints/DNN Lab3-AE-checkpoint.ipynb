{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49b90d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929c5c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Loading Dataset\n",
    "# Dataset link: https://data.mendeley.com/datasets/xvyv59vwvz/1\n",
    "# Dataset is present in the current directory containing the code file.\n",
    "df=pd.read_csv('../Datasets/ClaMP_Integrated-5184.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b488c60",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e919a469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_lfanew</th>\n",
       "      <th>NumberOfSections</th>\n",
       "      <th>CreationYear</th>\n",
       "      <th>FH_char0</th>\n",
       "      <th>FH_char1</th>\n",
       "      <th>...</th>\n",
       "      <th>sus_sections</th>\n",
       "      <th>non_sus_sections</th>\n",
       "      <th>packer</th>\n",
       "      <th>packer_type</th>\n",
       "      <th>E_text</th>\n",
       "      <th>E_data</th>\n",
       "      <th>filesize</th>\n",
       "      <th>E_file</th>\n",
       "      <th>fileinfo</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.603616</td>\n",
       "      <td>5.443362</td>\n",
       "      <td>1181520</td>\n",
       "      <td>6.627552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>5.205926</td>\n",
       "      <td>2.123522</td>\n",
       "      <td>7680</td>\n",
       "      <td>5.318221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>272</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.238000</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>57872</td>\n",
       "      <td>6.507758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95616</td>\n",
       "      <td>4.575092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.355626</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>48128</td>\n",
       "      <td>5.545531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_cblp  e_cp  e_cparhdr  e_maxalloc  e_sp  e_lfanew  NumberOfSections  \\\n",
       "0     144     3          4       65535   184       256                 4   \n",
       "1     144     3          4       65535   184       184                 4   \n",
       "2     144     3          4       65535   184       272                 5   \n",
       "3     144     3          4       65535   184       184                 1   \n",
       "4     144     3          4       65535   184       224                 5   \n",
       "\n",
       "   CreationYear  FH_char0  FH_char1  ...  sus_sections  non_sus_sections  \\\n",
       "0             1         0         1  ...             1                 3   \n",
       "1             1         0         1  ...             1                 3   \n",
       "2             1         0         1  ...             1                 4   \n",
       "3             1         0         1  ...             0                 1   \n",
       "4             1         0         1  ...             1                 4   \n",
       "\n",
       "   packer  packer_type    E_text    E_data  filesize    E_file  fileinfo  \\\n",
       "0       0     NoPacker  6.603616  5.443362   1181520  6.627552         1   \n",
       "1       0     NoPacker  5.205926  2.123522      7680  5.318221         0   \n",
       "2       0     NoPacker  6.238000  3.380859     57872  6.507758         1   \n",
       "3       0     NoPacker  0.000000  0.000000     95616  4.575092         1   \n",
       "4       0     NoPacker  6.355626  0.702621     48128  5.545531         1   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa639012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Null values with 0. ML classifer cannot learn on Null values\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "740bf015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_lfanew</th>\n",
       "      <th>NumberOfSections</th>\n",
       "      <th>CreationYear</th>\n",
       "      <th>FH_char0</th>\n",
       "      <th>FH_char1</th>\n",
       "      <th>...</th>\n",
       "      <th>sus_sections</th>\n",
       "      <th>non_sus_sections</th>\n",
       "      <th>packer</th>\n",
       "      <th>packer_type</th>\n",
       "      <th>E_text</th>\n",
       "      <th>E_data</th>\n",
       "      <th>filesize</th>\n",
       "      <th>E_file</th>\n",
       "      <th>fileinfo</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.603616</td>\n",
       "      <td>5.443362</td>\n",
       "      <td>1181520</td>\n",
       "      <td>6.627552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>5.205926</td>\n",
       "      <td>2.123522</td>\n",
       "      <td>7680</td>\n",
       "      <td>5.318221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>272</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.238000</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>57872</td>\n",
       "      <td>6.507758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95616</td>\n",
       "      <td>4.575092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65535</td>\n",
       "      <td>184</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.355626</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>48128</td>\n",
       "      <td>5.545531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_cblp  e_cp  e_cparhdr  e_maxalloc  e_sp  e_lfanew  NumberOfSections  \\\n",
       "0     144     3          4       65535   184       256                 4   \n",
       "1     144     3          4       65535   184       184                 4   \n",
       "2     144     3          4       65535   184       272                 5   \n",
       "3     144     3          4       65535   184       184                 1   \n",
       "4     144     3          4       65535   184       224                 5   \n",
       "\n",
       "   CreationYear  FH_char0  FH_char1  ...  sus_sections  non_sus_sections  \\\n",
       "0             1         0         1  ...             1                 3   \n",
       "1             1         0         1  ...             1                 3   \n",
       "2             1         0         1  ...             1                 4   \n",
       "3             1         0         1  ...             0                 1   \n",
       "4             1         0         1  ...             1                 4   \n",
       "\n",
       "   packer  packer_type    E_text    E_data  filesize    E_file  fileinfo  \\\n",
       "0       0     NoPacker  6.603616  5.443362   1181520  6.627552         1   \n",
       "1       0     NoPacker  5.205926  2.123522      7680  5.318221         0   \n",
       "2       0     NoPacker  6.238000  3.380859     57872  6.507758         1   \n",
       "3       0     NoPacker  0.000000  0.000000     95616  4.575092         1   \n",
       "4       0     NoPacker  6.355626  0.702621     48128  5.545531         1   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak on dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f479e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping these columns due to their insignificance\n",
    "df=df.drop(['NumberOfSections','CreationYear','e_cblp','e_cp','e_cparhdr','e_maxalloc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a8560f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5210, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfbee834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_lfanew</th>\n",
       "      <th>FH_char0</th>\n",
       "      <th>FH_char1</th>\n",
       "      <th>FH_char2</th>\n",
       "      <th>FH_char3</th>\n",
       "      <th>FH_char4</th>\n",
       "      <th>FH_char5</th>\n",
       "      <th>FH_char6</th>\n",
       "      <th>FH_char7</th>\n",
       "      <th>...</th>\n",
       "      <th>sus_sections</th>\n",
       "      <th>non_sus_sections</th>\n",
       "      <th>packer</th>\n",
       "      <th>packer_type</th>\n",
       "      <th>E_text</th>\n",
       "      <th>E_data</th>\n",
       "      <th>filesize</th>\n",
       "      <th>E_file</th>\n",
       "      <th>fileinfo</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.603616</td>\n",
       "      <td>5.443362</td>\n",
       "      <td>1181520</td>\n",
       "      <td>6.627552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>5.205926</td>\n",
       "      <td>2.123522</td>\n",
       "      <td>7680</td>\n",
       "      <td>5.318221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.238000</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>57872</td>\n",
       "      <td>6.507758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95616</td>\n",
       "      <td>4.575092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NoPacker</td>\n",
       "      <td>6.355626</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>48128</td>\n",
       "      <td>5.545531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_sp  e_lfanew  FH_char0  FH_char1  FH_char2  FH_char3  FH_char4  FH_char5  \\\n",
       "0   184       256         0         1         0         0         0         0   \n",
       "1   184       184         0         1         1         1         0         0   \n",
       "2   184       272         0         1         0         0         0         0   \n",
       "3   184       184         0         1         0         0         0         0   \n",
       "4   184       224         0         1         0         0         0         0   \n",
       "\n",
       "   FH_char6  FH_char7  ...  sus_sections  non_sus_sections  packer  \\\n",
       "0         0         1  ...             1                 3       0   \n",
       "1         0         1  ...             1                 3       0   \n",
       "2         0         1  ...             1                 4       0   \n",
       "3         0         1  ...             0                 1       0   \n",
       "4         0         1  ...             1                 4       0   \n",
       "\n",
       "   packer_type    E_text    E_data  filesize    E_file  fileinfo  class  \n",
       "0     NoPacker  6.603616  5.443362   1181520  6.627552         1      0  \n",
       "1     NoPacker  5.205926  2.123522      7680  5.318221         0      0  \n",
       "2     NoPacker  6.238000  3.380859     57872  6.507758         1      0  \n",
       "3     NoPacker  0.000000  0.000000     95616  4.575092         1      0  \n",
       "4     NoPacker  6.355626  0.702621     48128  5.545531         1      0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peak on the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e613e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodings Labels so that they are compatible with machine leanring classifiers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in df:\n",
    "    if df[i].dtype=='object':\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "    else:\n",
    "        continue\n",
    "X = df.drop(['class'],axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05c2946a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_lfanew</th>\n",
       "      <th>FH_char0</th>\n",
       "      <th>FH_char1</th>\n",
       "      <th>FH_char2</th>\n",
       "      <th>FH_char3</th>\n",
       "      <th>FH_char4</th>\n",
       "      <th>FH_char5</th>\n",
       "      <th>FH_char6</th>\n",
       "      <th>FH_char7</th>\n",
       "      <th>...</th>\n",
       "      <th>sus_sections</th>\n",
       "      <th>non_sus_sections</th>\n",
       "      <th>packer</th>\n",
       "      <th>packer_type</th>\n",
       "      <th>E_text</th>\n",
       "      <th>E_data</th>\n",
       "      <th>filesize</th>\n",
       "      <th>E_file</th>\n",
       "      <th>fileinfo</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.603616</td>\n",
       "      <td>5.443362</td>\n",
       "      <td>1181520</td>\n",
       "      <td>6.627552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>5.205926</td>\n",
       "      <td>2.123522</td>\n",
       "      <td>7680</td>\n",
       "      <td>5.318221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.238000</td>\n",
       "      <td>3.380859</td>\n",
       "      <td>57872</td>\n",
       "      <td>6.507758</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95616</td>\n",
       "      <td>4.575092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6.355626</td>\n",
       "      <td>0.702621</td>\n",
       "      <td>48128</td>\n",
       "      <td>5.545531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_sp  e_lfanew  FH_char0  FH_char1  FH_char2  FH_char3  FH_char4  FH_char5  \\\n",
       "0   184       256         0         1         0         0         0         0   \n",
       "1   184       184         0         1         1         1         0         0   \n",
       "2   184       272         0         1         0         0         0         0   \n",
       "3   184       184         0         1         0         0         0         0   \n",
       "4   184       224         0         1         0         0         0         0   \n",
       "\n",
       "   FH_char6  FH_char7  ...  sus_sections  non_sus_sections  packer  \\\n",
       "0         0         1  ...             1                 3       0   \n",
       "1         0         1  ...             1                 3       0   \n",
       "2         0         1  ...             1                 4       0   \n",
       "3         0         1  ...             0                 1       0   \n",
       "4         0         1  ...             1                 4       0   \n",
       "\n",
       "   packer_type    E_text    E_data  filesize    E_file  fileinfo  class  \n",
       "0           18  6.603616  5.443362   1181520  6.627552         1      0  \n",
       "1           18  5.205926  2.123522      7680  5.318221         0      0  \n",
       "2           18  6.238000  3.380859     57872  6.507758         1      0  \n",
       "3           18  0.000000  0.000000     95616  4.575092         1      0  \n",
       "4           18  6.355626  0.702621     48128  5.545531         1      0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check the features for the feature column \"Packer_type\". They are converted fr\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37df265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data into training, testing and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2637878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6cc38",
   "metadata": {},
   "source": [
    "# Scaling data. Default scaling is to scale the data to unit variance (or equivalent\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a076b",
   "metadata": {},
   "source": [
    "## Autoencoder reducing dims to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa2461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dims = 20\n",
    "current_dims = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9563ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "124/124 - 3s - loss: 0.1207 - val_loss: 0.0709\n",
      "Epoch 2/200\n",
      "124/124 - 1s - loss: 0.0265 - val_loss: 0.0335\n",
      "Epoch 3/200\n",
      "124/124 - 1s - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 4/200\n",
      "124/124 - 1s - loss: 0.0170 - val_loss: 0.0211\n",
      "Epoch 5/200\n",
      "124/124 - 1s - loss: 0.0147 - val_loss: 0.0187\n",
      "Epoch 6/200\n",
      "124/124 - 1s - loss: 0.0140 - val_loss: 0.0176\n",
      "Epoch 7/200\n",
      "124/124 - 1s - loss: 0.0130 - val_loss: 0.0163\n",
      "Epoch 8/200\n",
      "124/124 - 1s - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 9/200\n",
      "124/124 - 1s - loss: 0.0110 - val_loss: 0.0151\n",
      "Epoch 10/200\n",
      "124/124 - 1s - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 11/200\n",
      "124/124 - 1s - loss: 0.0103 - val_loss: 0.0151\n",
      "Epoch 12/200\n",
      "124/124 - 1s - loss: 0.0097 - val_loss: 0.0142\n",
      "Epoch 13/200\n",
      "124/124 - 1s - loss: 0.0092 - val_loss: 0.0143\n",
      "Epoch 14/200\n",
      "124/124 - 1s - loss: 0.0091 - val_loss: 0.0136\n",
      "Epoch 15/200\n",
      "124/124 - 1s - loss: 0.0088 - val_loss: 0.0134\n",
      "Epoch 16/200\n",
      "124/124 - 1s - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 17/200\n",
      "124/124 - 1s - loss: 0.0086 - val_loss: 0.0135\n",
      "Epoch 18/200\n",
      "124/124 - 1s - loss: 0.0078 - val_loss: 0.0130\n",
      "Epoch 19/200\n",
      "124/124 - 1s - loss: 0.0078 - val_loss: 0.0135\n",
      "Epoch 20/200\n",
      "124/124 - 1s - loss: 0.0076 - val_loss: 0.0125\n",
      "Epoch 21/200\n",
      "124/124 - 1s - loss: 0.0073 - val_loss: 0.0126\n",
      "Epoch 22/200\n",
      "124/124 - 1s - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 23/200\n",
      "124/124 - 1s - loss: 0.0074 - val_loss: 0.0129\n",
      "Epoch 24/200\n",
      "124/124 - 1s - loss: 0.0070 - val_loss: 0.0123\n",
      "Epoch 25/200\n",
      "124/124 - 1s - loss: 0.0068 - val_loss: 0.0127\n",
      "Epoch 26/200\n",
      "124/124 - 1s - loss: 0.0068 - val_loss: 0.0137\n",
      "Epoch 27/200\n",
      "124/124 - 1s - loss: 0.0068 - val_loss: 0.0123\n",
      "Epoch 28/200\n",
      "124/124 - 1s - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 29/200\n",
      "124/124 - 1s - loss: 0.0063 - val_loss: 0.0125\n",
      "Epoch 30/200\n",
      "124/124 - 1s - loss: 0.0064 - val_loss: 0.0121\n",
      "Epoch 31/200\n",
      "124/124 - 1s - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 32/200\n",
      "124/124 - 1s - loss: 0.0061 - val_loss: 0.0123\n",
      "Epoch 33/200\n",
      "124/124 - 1s - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 34/200\n",
      "124/124 - 1s - loss: 0.0061 - val_loss: 0.0121\n",
      "Epoch 35/200\n",
      "124/124 - 1s - loss: 0.0063 - val_loss: 0.0126\n",
      "Epoch 36/200\n",
      "124/124 - 1s - loss: 0.0058 - val_loss: 0.0122\n",
      "Epoch 37/200\n",
      "124/124 - 1s - loss: 0.0057 - val_loss: 0.0119\n",
      "Epoch 38/200\n",
      "124/124 - 1s - loss: 0.0054 - val_loss: 0.0126\n",
      "Epoch 39/200\n",
      "124/124 - 1s - loss: 0.0059 - val_loss: 0.0123\n",
      "Epoch 40/200\n",
      "124/124 - 1s - loss: 0.0053 - val_loss: 0.0116\n",
      "Epoch 41/200\n",
      "124/124 - 1s - loss: 0.0054 - val_loss: 0.0116\n",
      "Epoch 42/200\n",
      "124/124 - 1s - loss: 0.0054 - val_loss: 0.0126\n",
      "Epoch 43/200\n",
      "124/124 - 1s - loss: 0.0053 - val_loss: 0.0121\n",
      "Epoch 44/200\n",
      "124/124 - 1s - loss: 0.0050 - val_loss: 0.0115\n",
      "Epoch 45/200\n",
      "124/124 - 1s - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 46/200\n",
      "124/124 - 1s - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 47/200\n",
      "124/124 - 1s - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 48/200\n",
      "124/124 - 1s - loss: 0.0048 - val_loss: 0.0110\n",
      "Epoch 49/200\n",
      "124/124 - 1s - loss: 0.0049 - val_loss: 0.0113\n",
      "Epoch 50/200\n",
      "124/124 - 1s - loss: 0.0049 - val_loss: 0.0113\n",
      "Epoch 51/200\n",
      "124/124 - 1s - loss: 0.0047 - val_loss: 0.0112\n",
      "Epoch 52/200\n",
      "124/124 - 1s - loss: 0.0046 - val_loss: 0.0121\n",
      "Epoch 53/200\n",
      "124/124 - 1s - loss: 0.0049 - val_loss: 0.0118\n",
      "Epoch 54/200\n",
      "124/124 - 1s - loss: 0.0046 - val_loss: 0.0117\n",
      "Epoch 55/200\n",
      "124/124 - 1s - loss: 0.0049 - val_loss: 0.0123\n",
      "Epoch 56/200\n",
      "124/124 - 1s - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 57/200\n",
      "124/124 - 1s - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 58/200\n",
      "124/124 - 1s - loss: 0.0046 - val_loss: 0.0116\n",
      "Epoch 59/200\n",
      "124/124 - 1s - loss: 0.0046 - val_loss: 0.0124\n",
      "Epoch 60/200\n",
      "124/124 - 1s - loss: 0.0044 - val_loss: 0.0121\n",
      "Epoch 61/200\n",
      "124/124 - 1s - loss: 0.0044 - val_loss: 0.0109\n",
      "Epoch 62/200\n",
      "124/124 - 1s - loss: 0.0043 - val_loss: 0.0109\n",
      "Epoch 63/200\n",
      "124/124 - 1s - loss: 0.0042 - val_loss: 0.0111\n",
      "Epoch 64/200\n",
      "124/124 - 1s - loss: 0.0043 - val_loss: 0.0109\n",
      "Epoch 65/200\n",
      "124/124 - 1s - loss: 0.0041 - val_loss: 0.0108\n",
      "Epoch 66/200\n",
      "124/124 - 1s - loss: 0.0041 - val_loss: 0.0111\n",
      "Epoch 67/200\n",
      "124/124 - 1s - loss: 0.0040 - val_loss: 0.0105\n",
      "Epoch 68/200\n",
      "124/124 - 1s - loss: 0.0043 - val_loss: 0.0108\n",
      "Epoch 69/200\n",
      "124/124 - 1s - loss: 0.0042 - val_loss: 0.0106\n",
      "Epoch 70/200\n",
      "124/124 - 1s - loss: 0.0040 - val_loss: 0.0103\n",
      "Epoch 71/200\n",
      "124/124 - 1s - loss: 0.0039 - val_loss: 0.0112\n",
      "Epoch 72/200\n",
      "124/124 - 1s - loss: 0.0041 - val_loss: 0.0109\n",
      "Epoch 73/200\n",
      "124/124 - 1s - loss: 0.0038 - val_loss: 0.0103\n",
      "Epoch 74/200\n",
      "124/124 - 1s - loss: 0.0038 - val_loss: 0.0109\n",
      "Epoch 75/200\n",
      "124/124 - 1s - loss: 0.0041 - val_loss: 0.0112\n",
      "Epoch 76/200\n",
      "124/124 - 1s - loss: 0.0040 - val_loss: 0.0107\n",
      "Epoch 77/200\n",
      "124/124 - 1s - loss: 0.0039 - val_loss: 0.0110\n",
      "Epoch 78/200\n",
      "124/124 - 1s - loss: 0.0036 - val_loss: 0.0104\n",
      "Epoch 79/200\n",
      "124/124 - 1s - loss: 0.0037 - val_loss: 0.0105\n",
      "Epoch 80/200\n",
      "124/124 - 1s - loss: 0.0037 - val_loss: 0.0104\n",
      "Epoch 81/200\n",
      "124/124 - 1s - loss: 0.0038 - val_loss: 0.0105\n",
      "Epoch 82/200\n",
      "124/124 - 1s - loss: 0.0038 - val_loss: 0.0102\n",
      "Epoch 83/200\n",
      "124/124 - 1s - loss: 0.0038 - val_loss: 0.0102\n",
      "Epoch 84/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0101\n",
      "Epoch 85/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0105\n",
      "Epoch 86/200\n",
      "124/124 - 1s - loss: 0.0037 - val_loss: 0.0101\n",
      "Epoch 87/200\n",
      "124/124 - 1s - loss: 0.0036 - val_loss: 0.0109\n",
      "Epoch 88/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0101\n",
      "Epoch 89/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0103\n",
      "Epoch 90/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0104\n",
      "Epoch 91/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0106\n",
      "Epoch 92/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 93/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0102\n",
      "Epoch 94/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 95/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0101\n",
      "Epoch 96/200\n",
      "124/124 - 1s - loss: 0.0036 - val_loss: 0.0104\n",
      "Epoch 97/200\n",
      "124/124 - 1s - loss: 0.0033 - val_loss: 0.0102\n",
      "Epoch 98/200\n",
      "124/124 - 1s - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 99/200\n",
      "124/124 - 1s - loss: 0.0033 - val_loss: 0.0098\n",
      "Epoch 100/200\n",
      "124/124 - 1s - loss: 0.0035 - val_loss: 0.0098\n",
      "Epoch 101/200\n",
      "124/124 - 1s - loss: 0.0031 - val_loss: 0.0099\n",
      "Epoch 102/200\n",
      "124/124 - 1s - loss: 0.0034 - val_loss: 0.0099\n",
      "Epoch 103/200\n",
      "124/124 - 1s - loss: 0.0033 - val_loss: 0.0098\n",
      "Epoch 104/200\n",
      "124/124 - 1s - loss: 0.0032 - val_loss: 0.0097\n",
      "Epoch 105/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 106/200\n",
      "124/124 - 1s - loss: 0.0033 - val_loss: 0.0096\n",
      "Epoch 107/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 108/200\n",
      "124/124 - 1s - loss: 0.0033 - val_loss: 0.0101\n",
      "Epoch 109/200\n",
      "124/124 - 1s - loss: 0.0032 - val_loss: 0.0095\n",
      "Epoch 110/200\n",
      "124/124 - 1s - loss: 0.0032 - val_loss: 0.0099\n",
      "Epoch 111/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0097\n",
      "Epoch 112/200\n",
      "124/124 - 1s - loss: 0.0031 - val_loss: 0.0098\n",
      "Epoch 113/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0095\n",
      "Epoch 114/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 115/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0095\n",
      "Epoch 116/200\n",
      "124/124 - 1s - loss: 0.0031 - val_loss: 0.0095\n",
      "Epoch 117/200\n",
      "124/124 - 1s - loss: 0.0031 - val_loss: 0.0096\n",
      "Epoch 118/200\n",
      "124/124 - 1s - loss: 0.0031 - val_loss: 0.0095\n",
      "Epoch 119/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0094\n",
      "Epoch 120/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0099\n",
      "Epoch 121/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0095\n",
      "Epoch 122/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 123/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0097\n",
      "Epoch 124/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0098\n",
      "Epoch 125/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0098\n",
      "Epoch 126/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0097\n",
      "Epoch 127/200\n",
      "124/124 - 1s - loss: 0.0029 - val_loss: 0.0095\n",
      "Epoch 128/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0096\n",
      "Epoch 129/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 130/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0103\n",
      "Epoch 131/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0099\n",
      "Epoch 132/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0091\n",
      "Epoch 133/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 134/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0091\n",
      "Epoch 135/200\n",
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0094\n",
      "Epoch 136/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0094\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 - 1s - loss: 0.0030 - val_loss: 0.0093\n",
      "Epoch 138/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0091\n",
      "Epoch 139/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0093\n",
      "Epoch 140/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0096\n",
      "Epoch 141/200\n",
      "124/124 - 1s - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 142/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 143/200\n",
      "124/124 - 1s - loss: 0.0026 - val_loss: 0.0093\n",
      "Epoch 144/200\n",
      "124/124 - 1s - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 145/200\n",
      "124/124 - 1s - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 146/200\n",
      "124/124 - 1s - loss: 0.0026 - val_loss: 0.0092\n",
      "Epoch 147/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 148/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 149/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0091\n",
      "Epoch 150/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0092\n",
      "Epoch 151/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0093\n",
      "Epoch 152/200\n",
      "124/124 - 1s - loss: 0.0027 - val_loss: 0.0093\n",
      "Epoch 153/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0090\n",
      "Epoch 154/200\n",
      "124/124 - 1s - loss: 0.0024 - val_loss: 0.0091\n",
      "Epoch 155/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0096\n",
      "Epoch 156/200\n",
      "124/124 - 1s - loss: 0.0026 - val_loss: 0.0094\n",
      "Epoch 157/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0094\n",
      "Epoch 158/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 159/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 160/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0096\n",
      "Epoch 161/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 162/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 163/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0091\n",
      "Epoch 164/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0090\n",
      "Epoch 165/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0094\n",
      "Epoch 166/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0094\n",
      "Epoch 167/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0096\n",
      "Epoch 168/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0093\n",
      "Epoch 169/200\n",
      "124/124 - 1s - loss: 0.0024 - val_loss: 0.0092\n",
      "Epoch 170/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0092\n",
      "Epoch 171/200\n",
      "124/124 - 1s - loss: 0.0024 - val_loss: 0.0090\n",
      "Epoch 172/200\n",
      "124/124 - 1s - loss: 0.0025 - val_loss: 0.0094\n",
      "Epoch 173/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0089\n",
      "Epoch 174/200\n",
      "124/124 - 1s - loss: 0.0024 - val_loss: 0.0091\n",
      "Epoch 175/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0091\n",
      "Epoch 176/200\n",
      "124/124 - 1s - loss: 0.0024 - val_loss: 0.0093\n",
      "Epoch 177/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0093\n",
      "Epoch 178/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0087\n",
      "Epoch 179/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0093\n",
      "Epoch 180/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0090\n",
      "Epoch 181/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0090\n",
      "Epoch 182/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0090\n",
      "Epoch 183/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0092\n",
      "Epoch 184/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0090\n",
      "Epoch 185/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0089\n",
      "Epoch 186/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0093\n",
      "Epoch 187/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0092\n",
      "Epoch 188/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0089\n",
      "Epoch 189/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0092\n",
      "Epoch 190/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0088\n",
      "Epoch 191/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0090\n",
      "Epoch 192/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 193/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0092\n",
      "Epoch 194/200\n",
      "124/124 - 1s - loss: 0.0020 - val_loss: 0.0090\n",
      "Epoch 195/200\n",
      "124/124 - 1s - loss: 0.0023 - val_loss: 0.0092\n",
      "Epoch 196/200\n",
      "124/124 - 1s - loss: 0.0022 - val_loss: 0.0091\n",
      "Epoch 197/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0090\n",
      "Epoch 198/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 199/200\n",
      "124/124 - 1s - loss: 0.0020 - val_loss: 0.0088\n",
      "Epoch 200/200\n",
      "124/124 - 1s - loss: 0.0021 - val_loss: 0.0089\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define encoder\n",
    "visible = Input(shape=(current_dims,))\n",
    "# encoder level 1\n",
    "e = Dense(current_dims*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# encoder level 2\n",
    "'''e = Dense(current_dims)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)'''\n",
    "\n",
    "# bottleneck\n",
    "n_bottleneck = encoded_dims\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "\n",
    "# define decoder, level 1\n",
    "d = Dense(current_dims)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "# decoder level 2\n",
    "'''d = Dense(current_dims*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)'''\n",
    "# output layer\n",
    "output = Dense(current_dims, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "#plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
